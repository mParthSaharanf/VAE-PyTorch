model_params:
  name: 'BetaVAE'
  in_channels: 3
  latent_dim: 128
  loss_type: 'B'
  gamma: 10.0
  max_capacity: 25
  Capacity_max_iter: 10000

data_params:
  data_path: "Data/"
  train_batch_size: 64
  val_batch_size:  64
  patch_size: 64
  num_workers: 4
  
exp_params:
  LR: 0.005
  weight_decay: 0.0
  scheduler_gamma: 0.95
  kld_weight: 0.00025
  manual_seed: 1265

trainer_params:
  gpus: []
  max_epochs: 10
  auto_lr_find: False
  accumulate_grad_batches: 1  # Set to 1 for non-TPU training
  stochastic_weight_avg: False  # Set to True for training with SWA
  lr_scheduler:   # Add this section for learning rate scheduler configuration
    _target_: torch.optim.lr_scheduler.ExponentialLR  # Define the type of scheduler
    gamma: 0.95  # S

logging_params:
  save_dir: "logs/"
  manual_seed: 1265
  name: 'BetaVAE'
